{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from time import time as timer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split, Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at Sample Submissions, and labels CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "labels_csv = pd.read_csv(\"/kaggle/input/cifar-10/trainLabels.csv\")\n",
    "labels_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "labels_csv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Since the labels are stored as text in the DataFrame, we'll have to the map the labels to numbers\n",
    "label_mapping = {label: idx for idx, label in enumerate(labels_csv['label'].unique())}\n",
    "\n",
    "# Now let's encode them, and rename the text column\n",
    "labels_csv.rename({\"label\": \"label_txt\"}, axis=1, inplace=True)\n",
    "labels_csv['label'] = labels_csv['label_txt'].map(label_mapping)\n",
    "\n",
    "label_mapping, labels_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample_submissions_csv = pd.read_csv(\"/kaggle/input/cifar-10/sampleSubmission.csv\")\n",
    "sample_submissions_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the training images from the 7z folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# To extract the train and test images\n",
    "!sudo apt-get install p7zip-full\n",
    "!7z x \"/kaggle/input/cifar-10/train.7z\"\n",
    "!7z x \"/kaggle/input/cifar-10/test.7z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install py7zr\n",
    "import py7zr\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "archive_path = [\"/kaggle/input/cifar-10/train.7z\", \"/kaggle/input\"]\n",
    "extract_path = [\"/kaggle/working/train\", \"/kaggle/working/test\"]\n",
    "\n",
    "# Extract files\n",
    "with py7zr.SevenZipFile(archive_path, mode='r') as archive:\n",
    "    archive.extractall(path=extract_path)\n",
    "print(\"Extraction done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dir = \"/kaggle/working/train\"\n",
    "# test_dir = \"/kaggle/working/test\"\n",
    "\n",
    "train_imgs = os.listdir(train_dir)\n",
    "\n",
    "print(f\"Number of train images: {len(train_imgs)}\")\n",
    "print(f\"First 5 images' paths: {train_imgs[:5]}\")\n",
    "\n",
    "img1 = Image.open(train_dir + \"/\" + train_imgs[0])\n",
    "img1.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Image Transforms (For Sample Image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))    # To shift each pixel's value between -1 and 1, helping avoid exploding and vanishing gradients\n",
    "])\n",
    "\n",
    "img_tensor = transform(img1)\n",
    "img_tensor.shape   # Shape is 32x32x3, which tracks with how it should be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Train Image Transforms (utilizing Data Augmentation), and Test Image Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.2),   # Randomly flip about 20% images horizontally, to help model learn right-left symmetry\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),   # To shift each pixel's value between [-1, 1], helping avoid exploding and vanishing gradients\n",
    "])\n",
    "\n",
    "# RandomCrop not applied, because Cropping an image in the CIFAR-10 dataset may make the image inconclusive.\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data to DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Custom Dataset class in order to load the images as a torch.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images_dir, labels_csv, transform=None):\n",
    "        self.transforms = transform\n",
    "        self.imgs_dir = images_dir\n",
    "        self.labels_csv = labels_csv\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_csv)\n",
    "    \n",
    "    # Function to load each image, since we don't have the default structure that PyTorch wants it's Datasets to have\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = str(self.labels_csv.iloc[idx, 0]) + \".png\"    # Get file name of image with index \"idx\"\n",
    "        label = self.labels_csv.loc[idx, \"label\"]   # Get label of the image with index \"idx\"\n",
    "\n",
    "        img_path = os.path.join(self.imgs_dir, img_name)\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")   # Open the image in a PIL.Image format, and convert it to an RGB image\n",
    "\n",
    "        # Applying transforms\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "        \n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Creating the DataLoader for training data\n",
    "train_dataset = CustomDataset(\n",
    "    images_dir = \"/kaggle/working/train\", labels_csv = labels_csv,\n",
    "    transform = transform\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a CNN Architecture\n",
    "\n",
    "For the purpose of this problem, we'll be using the following architecture:\n",
    "\n",
    "* Input [ Dimensions: (Batch_size (32), 3, 32, 32) ]\n",
    "* First Convolution Layer [ (32, 3, 32, 32) -> (32, 32, 32, 32) ]\n",
    "* Second Convolution Layer [ (32, 32, 32, 32) -> (32, 64, 32, 32) ]\n",
    "* First Max Pooling Layer [ (32, 64, 32, 32) -> (32, 64, 16, 16) ]\n",
    "* Third Convolution Layer [ (32, 64, 16, 16) -> (32, 128, 16, 16) ]\n",
    "* Second Max Pooling Layer [ (32, 128, 16, 16) -> (32, 128, 8, 8) ]\n",
    "* Flatten Layer [ (32, 128, 8, 8) -> (32, 8192) ]\n",
    "* First FC Layer [ (32, 8192) -> (32, 256) ]\n",
    "* Second FC Layer [ (32, 256) -> (32, 128) ]\n",
    "* Dropout with keep_probability = 0.3\n",
    "* Output Layer [ (32, 128) -> (32, 10) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),  # Conv Layer 1\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # Conv Layer 2\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Max Pooling 1\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),  # Conv Layer 3\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # Max Pooling 2\n",
    "        )\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 8 * 8, 256),  # Fully connected layer 1\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),  # Fully connected layer 2\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),  # Dropout for regularization\n",
    "            nn.Linear(128, 10)  # Output layer (10 classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = CNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Shapes of all parameters\n",
    "for param in model.parameters():\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this particular problem, we'll be using the Cross Entropy loss function, and the Adam optimizer so we'll go ahead and set that up, before we make the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Setting the Loss criteria and the optimizer\n",
    "loss = nn.CrossEntropyLoss()   # Not MSE as this is not a regression problem, but a multi classification problem\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Migrating model to GPU, if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a simple training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, loss_fn, optimizer, device, n_epochs=50):\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch_num in range(1, n_epochs+1):\n",
    "        start_time = time()\n",
    "        model.train()    # Set the model to training model\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "    \n",
    "            optimizer.zero_grad()            # Reset gradients to 0\n",
    "    \n",
    "            outputs = model(images)           # Forward pass\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()                 # Start Backprop\n",
    "            \n",
    "            optimizer.step()                 # Update gradients\n",
    "    \n",
    "            running_loss += loss.item()\n",
    "    \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch_num}/{n_epochs}; Loss = {epoch_loss:.5f}; Time: {time()-start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Sample checking if training works\n",
    "train(train_loader, model, loss, optimizer, device, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, so now the loss is going down and the model is training correctly.\n",
    "\n",
    "Now there are 2 more things we need to implement: Early Stopping, and tracking metrics like Accuracy, Recall, Precision and F1 score.\n",
    "\n",
    "Accuracy = What percentage of predictions your model can make correctly\n",
    "Precision = What percentage of times when the model predicts a label is it correct\n",
    "Recall = What percentage of each label did the model correctly predict\n",
    "F1 - Harmonic Mean of Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# You cannot calculate metrics on your training data, and you can't do it on the testing set as well,\n",
    "# so we first need to create a training and validation set as well\n",
    "train_split = int(0.8 * len(train_dataset))\n",
    "val_split = int(0.2 * len(train_dataset))\n",
    "train_split, val_split\n",
    "\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_split, val_split])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping and Metrics Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience = 5, min_change = 0.001, checkpoint_pth = \"best_model.pth\"):\n",
    "        self.patience = patience\n",
    "        self.min_change = min_change\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        self.checkpoint_pth = checkpoint_pth\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if val_loss < self.best_loss - self.min_change:\n",
    "            counter = 0\n",
    "            self.best_loss = val_loss\n",
    "\n",
    "            torch.save(model.state_dict(), self.checkpoint_pth)\n",
    "        else:\n",
    "            self.counter += 1\n",
    "\n",
    "            print(f\"Early Stopping Counter: {self.counter}/{self.patience}\")\n",
    "            \n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "    def reset(self):\n",
    "        self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(model, val_loader, device):\n",
    "    model.eval()    # Set the model to evaluation mode\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(F.softmax(outputs, dim=1), dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Creating a more complex training function, with EarlyStopping and calculating all evaluation metrics\n",
    "early_stopper = EarlyStopping()\n",
    "\n",
    "def train(model, train_loader, val_loader, loss_fn, optimizer, early_stopper, device, n_epochs=5):\n",
    "    print(f\"Device being used: {device}\")\n",
    "    \n",
    "    model.to(device)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch_num in range(1, n_epochs+1):\n",
    "        start_time = timer()\n",
    "        model.train()    # Set the model to training model\n",
    "        train_loss = 0.0\n",
    "\n",
    "        # Training step\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "    \n",
    "            optimizer.zero_grad()            # Reset gradients to 0\n",
    "\n",
    "            outputs = model(images)           # Forward pass\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()                 # Start Backprop\n",
    "            \n",
    "            optimizer.step()                 # Update gradients\n",
    "    \n",
    "            train_loss += loss.item()\n",
    "    \n",
    "        train_loss /= len(train_loader)\n",
    "        accuracy, precision, recall, f1 = calculate_metrics(model, val_loader, device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "    \n",
    "        # Validation step\n",
    "        model.eval()    # Set the model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                print(images.dim())\n",
    "                outputs = model(images)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        print(\n",
    "            f\"Epoch {epoch_num}/{n_epochs};  Time: {timer()-start_time:.4f}; Train Loss = {train_loss:.4f};\",\n",
    "            f\"Validation Loss: {val_loss:.4f};\",\n",
    "            f\"Accuracy: {accuracy:.4f}; Precision: {precision:.4f}; Recall: {recall:.4f}; F1: {f1:.4f}; \"\n",
    "        )\n",
    "        \n",
    "        # Call Early Stopping\n",
    "        early_stopper(val_loss, model)\n",
    "        \n",
    "        if early_stopper.early_stop:\n",
    "            print(f\"Early Stopping Triggered. Best model saved at {early_stopper.checkpoint_pth}\")\n",
    "            break\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# train_losses, val_losses = train(model, train_loader, val_loader, loss, optimizer, early_stopper, device, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_train_and_val_losses(train_losses, val_losses):\n",
    "    plt.plot(train_losses, color='b', label='Training Loss')\n",
    "    plt.plot(val_losses, color='g', label='Validation Loss')\n",
    "\n",
    "    plt.title(\"Loss VS Epochs\")\n",
    "    plt.xlabel(\"Number of Epochs\")\n",
    "    plt.ylabel(\"Loss Value\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# plot_train_and_val_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this model is showing clear signs of overfitting. Let's apply weight decay, and increase the Dropout rate. The training function, EarlyStopping and calculate_metrics functions are working correctly, so let's adjust the basic architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CNN2(nn.Module):\n",
    "    def __init__(self, dropout_prob=0.5):\n",
    "        super(CNN2, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),  # Conv Layer 1\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # Conv Layer 2\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Max Pooling 1\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),  # Conv Layer 3\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # Max Pooling 2\n",
    "        )\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 8 * 8, 256),  # Fully connected layer 1\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),  # Fully connected layer 2\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),  # Dropout for regularization, increased to 0.5\n",
    "            nn.Linear(128, 10)  # Output layer (10 classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "# model2 = CNN2()\n",
    "# print(model2)\n",
    "\n",
    "# # Adding weight decay\n",
    "# optimizer = optim.Adam(model2.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Let's train this new model, and check how it fares\n",
    "# early_stopper2 = EarlyStopping(checkpoint_pth='best_model_v2.pth')\n",
    "\n",
    "# train_losses, val_losses = train(model2, train_loader, val_loader, loss, optimizer, early_stopper2, device, 10)\n",
    "# plot_train_and_val_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training absolutely poorly. Now it's underfitting, not learning at all. Likely a cause of high weight decay, and low learning rate.\n",
    "\n",
    "Trying a manual grid search of hyperparameters: lr, weight_decay, dropout_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dropout rate 0.3, LR = 1e-3, Weight Decay = 1e-10\n",
    "# model3 = CNN2(0.3)\n",
    "# optimizer3 = optim.Adam(model3.parameters(), lr=1e-3, weight_decay=1e-10)\n",
    "\n",
    "# early_stopper3 = EarlyStopping(checkpoint_pth='best_model_v3.pth')\n",
    "\n",
    "# train_losses, val_losses = train(model3, train_loader, val_loader, loss, optimizer3, early_stopper3, device, 10)\n",
    "# plot_train_and_val_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dropout rate 0.3, LR = 1e-1, Weight Decay = 1e-4\n",
    "# model4 = CNN2(0.3)\n",
    "# optimizer4 = optim.Adam(model4.parameters(), lr=1e-1, weight_decay=1e-4)\n",
    "\n",
    "# early_stopper4 = EarlyStopping(checkpoint_pth='best_model_v4.pth')\n",
    "\n",
    "# train_losses, val_losses = train(model4, train_loader, val_loader, loss, optimizer4, early_stopper4, device, 10)\n",
    "# plot_train_and_val_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dropout rate 0.5, LR = 1e-3, Weight Decay = 1e-10\n",
    "# model5 = CNN2(0.5)\n",
    "# optimizer5 = optim.Adam(model5.parameters(), lr=1e-3, weight_decay=1e-10)\n",
    "\n",
    "# early_stopper5 = EarlyStopping(checkpoint_pth='best_model_v5.pth')\n",
    "\n",
    "# train_losses, val_losses = train(model5, train_loader, val_loader, loss, optimizer5, early_stopper5, device, 10)\n",
    "# plot_train_and_val_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dropout rate 0.5, LR = 1e-1, Weight Decay = 1e-4\n",
    "# model6 = CNN2(0.5)\n",
    "# optimizer6 = optim.Adam(model6.parameters(), lr=1e-1, weight_decay=1e-4)\n",
    "\n",
    "# early_stopper6 = EarlyStopping(checkpoint_pth='best_model_v5.pth')\n",
    "\n",
    "# train_losses, val_losses = train(model6, train_loader, val_loader, loss, optimizer6, early_stopper6, device, 10)\n",
    "# plot_train_and_val_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dropout rate 0.3, LR = 1e-3, Weight Decay = 1e-4\n",
    "# model7 = CNN2(0.3)\n",
    "# optimizer7 = optim.Adam(model7.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "# early_stopper7 = EarlyStopping(checkpoint_pth='best_model_v5.pth')\n",
    "\n",
    "# train_losses, val_losses = train(model7, train_loader, val_loader, loss, optimizer7, early_stopper7, device, 10)\n",
    "# plot_train_and_val_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing weight decay, adding BatchNorm after every layer, and reducing Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CNN3(nn.Module):\n",
    "    def __init__(self, dropout_prob=0.3):\n",
    "        super(CNN3, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),  # Conv Layer 1\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # Conv Layer 2\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Max Pooling 1\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),  # Conv Layer 3\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # Max Pooling 2\n",
    "        )\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 8 * 8, 256),  # Fully connected layer 1\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),  # Fully connected layer 2\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),  # Dropout for regularization, increased to 0.5\n",
    "            nn.Linear(128, 10)  # Output layer (10 classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Creating a more complex training function, with EarlyStopping and calculating all evaluation metrics\n",
    "def train(model, train_loader, val_loader, loss_fn, optimizer, early_stopper, device, n_epochs=5):\n",
    "    print(f\"Device being used: {device}\")\n",
    "    \n",
    "    model.to(device)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch_num in range(1, n_epochs+1):\n",
    "        start_time = timer()\n",
    "        model.train()    # Set the model to training model\n",
    "        train_loss = 0.0\n",
    "\n",
    "        # Training step\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "    \n",
    "            optimizer.zero_grad()             # Reset gradients to 0\n",
    "\n",
    "            outputs = model(images)           # Forward pass\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()                   # Start Backprop\n",
    "            \n",
    "            optimizer.step()                  # Update gradients\n",
    "    \n",
    "            train_loss += loss.item()\n",
    "    \n",
    "        train_loss /= len(train_loader)\n",
    "        accuracy, precision, recall, f1 = calculate_metrics(model, val_loader, device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "    \n",
    "        # Validation step\n",
    "        model.eval()    # Set the model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        print(\n",
    "            f\"Epoch {epoch_num}/{n_epochs} |  Time: {timer()-start_time:.2f} | Train Loss = {train_loss:.4f} |\",\n",
    "            f\"Validation Loss: {val_loss:.4f} |\",\n",
    "            f\"Accuracy: {accuracy:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f}; \"\n",
    "        )\n",
    "        \n",
    "        # Call Early Stopping\n",
    "        early_stopper(val_loss, model)\n",
    "        \n",
    "        if early_stopper.early_stop:\n",
    "            print(f\"Early Stopping Triggered. Best model saved at {early_stopper.checkpoint_pth}\")\n",
    "            break\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Reducing the Dropout probability\n",
    "# model3_1 = CNN3(dropout_prob=0.2)\n",
    "# optimizer3_1 = optim.Adam(model3_1.parameters(), lr=5e-4)\n",
    "\n",
    "# earlyStopper3_1 = EarlyStopping(checkpoint_pth = 'best_model3_1.pth')\n",
    "\n",
    "# train(model3_1, train_loader, val_loader, loss, optimizer3_1, earlyStopper3_1, device, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Increasing the Dropout probability alongside BatchNorm\n",
    "# model3_2 = CNN3(dropout_prob=0.5)\n",
    "# optimizer3_2 = optim.Adam(model3_2.parameters(), lr=5e-4)\n",
    "\n",
    "# earlyStopper3_2 = EarlyStopping(checkpoint_pth = 'best_model3_2.pth')\n",
    "\n",
    "# train(model3_2, train_loader, val_loader, loss, optimizer3_2, earlyStopper3_2, device, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trend shows that increasing the Dropout rate alongside having BatchNorm is making the training smoother. Let's test the theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model3_3 = CNN3(dropout_prob=0.7)\n",
    "# optimizer3_3 = optim.Adam(model3_3.parameters(), lr=5e-4)\n",
    "\n",
    "# earlyStopper3_3 = EarlyStopping(checkpoint_pth = 'best_model3_3.pth')\n",
    "\n",
    "# train_losses, val_losses = train(model3_3, train_loader, val_loader, loss, optimizer3_3, earlyStopper3_3, device, 10)\n",
    "# plot_train_and_val_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Increasing the Learning Rate\n",
    "model3_3 = CNN3(dropout_prob=0.7)\n",
    "optimizer3_3 = optim.Adam(model3_3.parameters(), lr=1e-3)\n",
    "\n",
    "earlyStopper3_3 = EarlyStopping(checkpoint_pth = 'best_model3_3.pth')\n",
    "\n",
    "train_losses, val_losses = train(model3_3, train_loader, val_loader, loss, optimizer3_3, earlyStopper3_3, device, 10)\n",
    "plot_train_and_val_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So accuracy is increasing on the validation set, but the disparity between the losses is increasing.\n",
    "\n",
    "So far the best model is the last one that was trained, stored in \"best_model3_3.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Unpacking the test images, and applying transforms\n",
    "!7z x \"/kaggle/input/cifar-10/test.7z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Creating a custom Dataset class and the DataLoader\n",
    "\n",
    "class CustomTestDataset(Dataset):\n",
    "    def __init__(self, images_dir, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        self.img_files = sorted(os.listdir(images_dir))  # Ensure correct order\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.images_dir, self.img_files[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # Open image as RGB\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, self.img_files[idx]\n",
    "\n",
    "\n",
    "test_dataset = CustomTestDataset(\"/kaggle/working/test\", test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loading best model\n",
    "model = CNN3()\n",
    "model.load_state_dict(torch.load(\"best_model3_3.pth\"))  \n",
    "model.to(device)\n",
    "model.eval()     # Set to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "all_preds = []\n",
    "img_idxs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, idxs in test_loader:\n",
    "        images = images.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        img_idxs.extend(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Re-mapping predictions\n",
    "idxs_to_classes = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "predicted_labels = [idxs_to_classes[pred] for pred in all_preds]\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    \"id\": [int(file.split(\".\")[0]) for file in img_idxs],  \n",
    "    \"label\": predicted_labels\n",
    "})\n",
    "\n",
    "# Sort by ID to ensure correct order\n",
    "submission_df = submission_df.sort_values(by=\"id\")\n",
    "\n",
    "# Save to CSV\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 46718,
     "sourceId": 3649,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
